{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f62d0b5e-b652-4d78-b710-cf59fc6240a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from pycaret.classification import setup, evaluate_model, compare_models, plot_model, add_metric\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa67a04-088b-4b4d-8815-36f6f666e0d6",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fba91969-ff40-4993-a22c-1f096d18eb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', index_col='id')\n",
    "test = pd.read_csv('test.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ebc26a-233a-4840-9f27-b8fd01f96eee",
   "metadata": {},
   "source": [
    "# Brief EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b5f9e41-7c54-4bf1-951f-4a53d7859185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(707, 65)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a42e4a9-dba1-43b7-90e0-351baa129104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "981c2e0b-65fc-4a80-9cec-8c8ee6400ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sudden_fever</th>\n",
       "      <th>headache</th>\n",
       "      <th>mouth_bleed</th>\n",
       "      <th>nose_bleed</th>\n",
       "      <th>muscle_pain</th>\n",
       "      <th>joint_pain</th>\n",
       "      <th>vomiting</th>\n",
       "      <th>rash</th>\n",
       "      <th>diarrhea</th>\n",
       "      <th>hypotension</th>\n",
       "      <th>...</th>\n",
       "      <th>lymph_swells</th>\n",
       "      <th>breathing_restriction</th>\n",
       "      <th>toe_inflammation</th>\n",
       "      <th>finger_inflammation</th>\n",
       "      <th>lips_irritation</th>\n",
       "      <th>itchiness</th>\n",
       "      <th>ulcers</th>\n",
       "      <th>toenail_loss</th>\n",
       "      <th>speech_problem</th>\n",
       "      <th>bullseye_rash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>707.000000</td>\n",
       "      <td>707.000000</td>\n",
       "      <td>707.000000</td>\n",
       "      <td>707.000000</td>\n",
       "      <td>707.000000</td>\n",
       "      <td>707.000000</td>\n",
       "      <td>707.000000</td>\n",
       "      <td>707.000000</td>\n",
       "      <td>707.000000</td>\n",
       "      <td>707.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>707.000000</td>\n",
       "      <td>707.000000</td>\n",
       "      <td>707.000000</td>\n",
       "      <td>707.000000</td>\n",
       "      <td>707.000000</td>\n",
       "      <td>707.000000</td>\n",
       "      <td>707.000000</td>\n",
       "      <td>707.000000</td>\n",
       "      <td>707.000000</td>\n",
       "      <td>707.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.503536</td>\n",
       "      <td>0.449788</td>\n",
       "      <td>0.459689</td>\n",
       "      <td>0.487977</td>\n",
       "      <td>0.517680</td>\n",
       "      <td>0.449788</td>\n",
       "      <td>0.441301</td>\n",
       "      <td>0.487977</td>\n",
       "      <td>0.390382</td>\n",
       "      <td>0.393211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.072136</td>\n",
       "      <td>0.097595</td>\n",
       "      <td>0.079208</td>\n",
       "      <td>0.084866</td>\n",
       "      <td>0.154173</td>\n",
       "      <td>0.144272</td>\n",
       "      <td>0.137199</td>\n",
       "      <td>0.032532</td>\n",
       "      <td>0.031117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500341</td>\n",
       "      <td>0.497825</td>\n",
       "      <td>0.498725</td>\n",
       "      <td>0.500209</td>\n",
       "      <td>0.500041</td>\n",
       "      <td>0.497825</td>\n",
       "      <td>0.496894</td>\n",
       "      <td>0.500209</td>\n",
       "      <td>0.488181</td>\n",
       "      <td>0.488809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355861</td>\n",
       "      <td>0.258896</td>\n",
       "      <td>0.296977</td>\n",
       "      <td>0.270254</td>\n",
       "      <td>0.278879</td>\n",
       "      <td>0.361370</td>\n",
       "      <td>0.351614</td>\n",
       "      <td>0.344301</td>\n",
       "      <td>0.177533</td>\n",
       "      <td>0.173758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sudden_fever    headache  mouth_bleed  nose_bleed  muscle_pain  \\\n",
       "count    707.000000  707.000000   707.000000  707.000000   707.000000   \n",
       "mean       0.503536    0.449788     0.459689    0.487977     0.517680   \n",
       "std        0.500341    0.497825     0.498725    0.500209     0.500041   \n",
       "min        0.000000    0.000000     0.000000    0.000000     0.000000   \n",
       "25%        0.000000    0.000000     0.000000    0.000000     0.000000   \n",
       "50%        1.000000    0.000000     0.000000    0.000000     1.000000   \n",
       "75%        1.000000    1.000000     1.000000    1.000000     1.000000   \n",
       "max        1.000000    1.000000     1.000000    1.000000     1.000000   \n",
       "\n",
       "       joint_pain    vomiting        rash    diarrhea  hypotension  ...  \\\n",
       "count  707.000000  707.000000  707.000000  707.000000   707.000000  ...   \n",
       "mean     0.449788    0.441301    0.487977    0.390382     0.393211  ...   \n",
       "std      0.497825    0.496894    0.500209    0.488181     0.488809  ...   \n",
       "min      0.000000    0.000000    0.000000    0.000000     0.000000  ...   \n",
       "25%      0.000000    0.000000    0.000000    0.000000     0.000000  ...   \n",
       "50%      0.000000    0.000000    0.000000    0.000000     0.000000  ...   \n",
       "75%      1.000000    1.000000    1.000000    1.000000     1.000000  ...   \n",
       "max      1.000000    1.000000    1.000000    1.000000     1.000000  ...   \n",
       "\n",
       "       lymph_swells  breathing_restriction  toe_inflammation  \\\n",
       "count    707.000000             707.000000        707.000000   \n",
       "mean       0.148515               0.072136          0.097595   \n",
       "std        0.355861               0.258896          0.296977   \n",
       "min        0.000000               0.000000          0.000000   \n",
       "25%        0.000000               0.000000          0.000000   \n",
       "50%        0.000000               0.000000          0.000000   \n",
       "75%        0.000000               0.000000          0.000000   \n",
       "max        1.000000               1.000000          1.000000   \n",
       "\n",
       "       finger_inflammation  lips_irritation   itchiness      ulcers  \\\n",
       "count           707.000000       707.000000  707.000000  707.000000   \n",
       "mean              0.079208         0.084866    0.154173    0.144272   \n",
       "std               0.270254         0.278879    0.361370    0.351614   \n",
       "min               0.000000         0.000000    0.000000    0.000000   \n",
       "25%               0.000000         0.000000    0.000000    0.000000   \n",
       "50%               0.000000         0.000000    0.000000    0.000000   \n",
       "75%               0.000000         0.000000    0.000000    0.000000   \n",
       "max               1.000000         1.000000    1.000000    1.000000   \n",
       "\n",
       "       toenail_loss  speech_problem  bullseye_rash  \n",
       "count    707.000000      707.000000     707.000000  \n",
       "mean       0.137199        0.032532       0.031117  \n",
       "std        0.344301        0.177533       0.173758  \n",
       "min        0.000000        0.000000       0.000000  \n",
       "25%        0.000000        0.000000       0.000000  \n",
       "50%        0.000000        0.000000       0.000000  \n",
       "75%        0.000000        0.000000       0.000000  \n",
       "max        1.000000        1.000000       1.000000  \n",
       "\n",
       "[8 rows x 64 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "629295b5-c1e3-4884-ac88-eb65640db0ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sudden_fever</th>\n",
       "      <th>headache</th>\n",
       "      <th>mouth_bleed</th>\n",
       "      <th>nose_bleed</th>\n",
       "      <th>muscle_pain</th>\n",
       "      <th>joint_pain</th>\n",
       "      <th>vomiting</th>\n",
       "      <th>rash</th>\n",
       "      <th>diarrhea</th>\n",
       "      <th>hypotension</th>\n",
       "      <th>...</th>\n",
       "      <th>breathing_restriction</th>\n",
       "      <th>toe_inflammation</th>\n",
       "      <th>finger_inflammation</th>\n",
       "      <th>lips_irritation</th>\n",
       "      <th>itchiness</th>\n",
       "      <th>ulcers</th>\n",
       "      <th>toenail_loss</th>\n",
       "      <th>speech_problem</th>\n",
       "      <th>bullseye_rash</th>\n",
       "      <th>prognosis</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lyme_disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tungiasis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Lyme_disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Zika</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rift_Valley_fever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sudden_fever  headache  mouth_bleed  nose_bleed  muscle_pain  joint_pain  \\\n",
       "id                                                                             \n",
       "0            1.0       1.0          0.0         1.0          1.0         1.0   \n",
       "1            0.0       0.0          0.0         0.0          0.0         0.0   \n",
       "2            0.0       1.0          1.0         1.0          0.0         1.0   \n",
       "3            0.0       0.0          1.0         1.0          1.0         1.0   \n",
       "4            0.0       0.0          0.0         0.0          0.0         0.0   \n",
       "\n",
       "    vomiting  rash  diarrhea  hypotension  ...  breathing_restriction  \\\n",
       "id                                         ...                          \n",
       "0        1.0   0.0       1.0          1.0  ...                    0.0   \n",
       "1        1.0   0.0       1.0          0.0  ...                    0.0   \n",
       "2        1.0   1.0       1.0          1.0  ...                    1.0   \n",
       "3        0.0   1.0       0.0          1.0  ...                    0.0   \n",
       "4        0.0   0.0       1.0          0.0  ...                    0.0   \n",
       "\n",
       "    toe_inflammation  finger_inflammation  lips_irritation  itchiness  ulcers  \\\n",
       "id                                                                              \n",
       "0                0.0                  0.0              0.0        0.0     0.0   \n",
       "1                0.0                  0.0              0.0        0.0     0.0   \n",
       "2                1.0                  1.0              1.0        1.0     0.0   \n",
       "3                0.0                  0.0              0.0        0.0     0.0   \n",
       "4                1.0                  0.0              0.0        1.0     1.0   \n",
       "\n",
       "    toenail_loss  speech_problem  bullseye_rash          prognosis  \n",
       "id                                                                  \n",
       "0            0.0             0.0            0.0       Lyme_disease  \n",
       "1            0.0             0.0            0.0          Tungiasis  \n",
       "2            1.0             1.0            1.0       Lyme_disease  \n",
       "3            0.0             0.0            0.0               Zika  \n",
       "4            1.0             0.0            0.0  Rift_Valley_fever  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19c8251f-69ff-4a25-9d42-c6a35b99bf1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "West_Nile_fever          85\n",
       "Japanese_encephalitis    81\n",
       "Tungiasis                70\n",
       "Rift_Valley_fever        70\n",
       "Chikungunya              66\n",
       "Dengue                   63\n",
       "Yellow_Fever             61\n",
       "Zika                     58\n",
       "Plague                   53\n",
       "Lyme_disease             52\n",
       "Malaria                  48\n",
       "Name: prognosis, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = train.prognosis\n",
    "X = train.drop('prognosis', axis=1)\n",
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7a6def-53ba-45b7-a939-d3f968b07338",
   "metadata": {},
   "source": [
    "# Target transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23d6c825-9947-47dc-8e05-c2e03d14024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beb36e2a-879f-42b5-9089-1add94488180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        # first condition checks whether it is valid prediction\n",
    "        # second condition checks if prediction is not repeated\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=3):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a43321-4e15-49f0-bf3a-6c164dd12bc3",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b043ce91-3dc6-4110-a515-9192e1c5b002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6c1d9_row9_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6c1d9_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6c1d9_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_6c1d9_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_6c1d9_row0_col1\" class=\"data row0 col1\" >4384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c1d9_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_6c1d9_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_6c1d9_row1_col1\" class=\"data row1 col1\" >prognosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c1d9_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_6c1d9_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_6c1d9_row2_col1\" class=\"data row2 col1\" >Multiclass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c1d9_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_6c1d9_row3_col0\" class=\"data row3 col0\" >Target mapping</td>\n",
       "      <td id=\"T_6c1d9_row3_col1\" class=\"data row3 col1\" >Chikungunya: 0, Dengue: 1, Japanese_encephalitis: 2, Lyme_disease: 3, Malaria: 4, Plague: 5, Rift_Valley_fever: 6, Tungiasis: 7, West_Nile_fever: 8, Yellow_Fever: 9, Zika: 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c1d9_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_6c1d9_row4_col0\" class=\"data row4 col0\" >Original data shape</td>\n",
       "      <td id=\"T_6c1d9_row4_col1\" class=\"data row4 col1\" >(707, 65)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c1d9_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_6c1d9_row5_col0\" class=\"data row5 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_6c1d9_row5_col1\" class=\"data row5 col1\" >(707, 65)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c1d9_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_6c1d9_row6_col0\" class=\"data row6 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_6c1d9_row6_col1\" class=\"data row6 col1\" >(494, 65)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c1d9_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_6c1d9_row7_col0\" class=\"data row7 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_6c1d9_row7_col1\" class=\"data row7 col1\" >(213, 65)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c1d9_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_6c1d9_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n",
       "      <td id=\"T_6c1d9_row8_col1\" class=\"data row8 col1\" >64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c1d9_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_6c1d9_row9_col0\" class=\"data row9 col0\" >Preprocess</td>\n",
       "      <td id=\"T_6c1d9_row9_col1\" class=\"data row9 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c1d9_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_6c1d9_row10_col0\" class=\"data row10 col0\" >Imputation type</td>\n",
       "      <td id=\"T_6c1d9_row10_col1\" class=\"data row10 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c1d9_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_6c1d9_row11_col0\" class=\"data row11 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_6c1d9_row11_col1\" class=\"data row11 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c1d9_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_6c1d9_row12_col0\" class=\"data row12 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_6c1d9_row12_col1\" class=\"data row12 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c1d9_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_6c1d9_row13_col0\" class=\"data row13 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_6c1d9_row13_col1\" class=\"data row13 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c1d9_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_6c1d9_row14_col0\" class=\"data row14 col0\" >Fold Number</td>\n",
       "      <td id=\"T_6c1d9_row14_col1\" class=\"data row14 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c1d9_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_6c1d9_row15_col0\" class=\"data row15 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_6c1d9_row15_col1\" class=\"data row15 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c1d9_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_6c1d9_row16_col0\" class=\"data row16 col0\" >Use GPU</td>\n",
       "      <td id=\"T_6c1d9_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c1d9_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_6c1d9_row17_col0\" class=\"data row17 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_6c1d9_row17_col1\" class=\"data row17 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c1d9_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_6c1d9_row18_col0\" class=\"data row18 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_6c1d9_row18_col1\" class=\"data row18 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6c1d9_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_6c1d9_row19_col0\" class=\"data row19 col0\" >USI</td>\n",
       "      <td id=\"T_6c1d9_row19_col1\" class=\"data row19 col1\" >25f9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x20b9e08f408>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = setup(data=train, target='prognosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "756f817a-7827-4e5f-a63d-dd0b5b4ad0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                                                  MAPK\n",
       "Display Name                                          MAPK\n",
       "Score Function       <function mapk at 0x0000020BA0EE4AF8>\n",
       "Scorer                                   make_scorer(mapk)\n",
       "Target                                                pred\n",
       "Args                                                    {}\n",
       "Greater is Better                                     True\n",
       "Multiclass                                            True\n",
       "Custom                                                True\n",
       "Name: mapk, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_metric(id='mapk', name='MAPK', score_func=mapk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b607567-9496-4256-a042-bb05442720cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b622e_ th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_b622e_row0_col0, #T_b622e_row0_col6, #T_b622e_row0_col7, #T_b622e_row0_col8, #T_b622e_row1_col0, #T_b622e_row1_col1, #T_b622e_row1_col2, #T_b622e_row1_col3, #T_b622e_row1_col4, #T_b622e_row1_col5, #T_b622e_row2_col0, #T_b622e_row2_col1, #T_b622e_row2_col2, #T_b622e_row2_col3, #T_b622e_row2_col4, #T_b622e_row2_col5, #T_b622e_row2_col6, #T_b622e_row2_col7, #T_b622e_row2_col8, #T_b622e_row3_col0, #T_b622e_row3_col1, #T_b622e_row3_col2, #T_b622e_row3_col3, #T_b622e_row3_col4, #T_b622e_row3_col5, #T_b622e_row3_col6, #T_b622e_row3_col7, #T_b622e_row3_col8, #T_b622e_row4_col0, #T_b622e_row4_col1, #T_b622e_row4_col2, #T_b622e_row4_col3, #T_b622e_row4_col4, #T_b622e_row4_col5, #T_b622e_row4_col6, #T_b622e_row4_col7, #T_b622e_row4_col8, #T_b622e_row5_col0, #T_b622e_row5_col1, #T_b622e_row5_col2, #T_b622e_row5_col3, #T_b622e_row5_col4, #T_b622e_row5_col5, #T_b622e_row5_col6, #T_b622e_row5_col7, #T_b622e_row5_col8, #T_b622e_row6_col0, #T_b622e_row6_col1, #T_b622e_row6_col2, #T_b622e_row6_col3, #T_b622e_row6_col4, #T_b622e_row6_col5, #T_b622e_row6_col6, #T_b622e_row6_col7, #T_b622e_row6_col8, #T_b622e_row7_col0, #T_b622e_row7_col1, #T_b622e_row7_col2, #T_b622e_row7_col3, #T_b622e_row7_col4, #T_b622e_row7_col5, #T_b622e_row7_col6, #T_b622e_row7_col7, #T_b622e_row7_col8, #T_b622e_row8_col0, #T_b622e_row8_col1, #T_b622e_row8_col2, #T_b622e_row8_col3, #T_b622e_row8_col4, #T_b622e_row8_col5, #T_b622e_row8_col6, #T_b622e_row8_col7, #T_b622e_row8_col8, #T_b622e_row9_col0, #T_b622e_row9_col1, #T_b622e_row9_col2, #T_b622e_row9_col3, #T_b622e_row9_col4, #T_b622e_row9_col5, #T_b622e_row9_col6, #T_b622e_row9_col7, #T_b622e_row9_col8, #T_b622e_row10_col0, #T_b622e_row10_col1, #T_b622e_row10_col2, #T_b622e_row10_col3, #T_b622e_row10_col4, #T_b622e_row10_col5, #T_b622e_row10_col6, #T_b622e_row10_col7, #T_b622e_row10_col8, #T_b622e_row11_col0, #T_b622e_row11_col1, #T_b622e_row11_col2, #T_b622e_row11_col3, #T_b622e_row11_col4, #T_b622e_row11_col5, #T_b622e_row11_col6, #T_b622e_row11_col7, #T_b622e_row11_col8, #T_b622e_row12_col0, #T_b622e_row12_col1, #T_b622e_row12_col2, #T_b622e_row12_col3, #T_b622e_row12_col4, #T_b622e_row12_col5, #T_b622e_row12_col6, #T_b622e_row12_col7, #T_b622e_row12_col8, #T_b622e_row13_col0, #T_b622e_row13_col1, #T_b622e_row13_col2, #T_b622e_row13_col3, #T_b622e_row13_col4, #T_b622e_row13_col5, #T_b622e_row13_col6, #T_b622e_row13_col7, #T_b622e_row13_col8, #T_b622e_row14_col0, #T_b622e_row14_col1, #T_b622e_row14_col2, #T_b622e_row14_col3, #T_b622e_row14_col4, #T_b622e_row14_col5, #T_b622e_row14_col6, #T_b622e_row14_col7, #T_b622e_row14_col8 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_b622e_row0_col1, #T_b622e_row0_col2, #T_b622e_row0_col3, #T_b622e_row0_col4, #T_b622e_row0_col5, #T_b622e_row1_col6, #T_b622e_row1_col7, #T_b622e_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_b622e_row0_col9, #T_b622e_row1_col9, #T_b622e_row2_col9, #T_b622e_row3_col9, #T_b622e_row4_col9, #T_b622e_row5_col9, #T_b622e_row6_col9, #T_b622e_row7_col9, #T_b622e_row8_col9, #T_b622e_row9_col9, #T_b622e_row11_col9, #T_b622e_row12_col9, #T_b622e_row13_col9, #T_b622e_row14_col9 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_b622e_row10_col9 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b622e_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th class=\"col_heading level0 col8\" >MAPK</th>\n",
       "      <th class=\"col_heading level0 col9\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b622e_level0_row0\" class=\"row_heading level0 row0\" >et</th>\n",
       "      <td id=\"T_b622e_row0_col0\" class=\"data row0 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_b622e_row0_col1\" class=\"data row0 col1\" >0.2938</td>\n",
       "      <td id=\"T_b622e_row0_col2\" class=\"data row0 col2\" >0.7496</td>\n",
       "      <td id=\"T_b622e_row0_col3\" class=\"data row0 col3\" >0.2938</td>\n",
       "      <td id=\"T_b622e_row0_col4\" class=\"data row0 col4\" >0.3004</td>\n",
       "      <td id=\"T_b622e_row0_col5\" class=\"data row0 col5\" >0.2824</td>\n",
       "      <td id=\"T_b622e_row0_col6\" class=\"data row0 col6\" >0.2202</td>\n",
       "      <td id=\"T_b622e_row0_col7\" class=\"data row0 col7\" >0.2224</td>\n",
       "      <td id=\"T_b622e_row0_col8\" class=\"data row0 col8\" >0.3966</td>\n",
       "      <td id=\"T_b622e_row0_col9\" class=\"data row0 col9\" >0.1940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b622e_level0_row1\" class=\"row_heading level0 row1\" >lda</th>\n",
       "      <td id=\"T_b622e_row1_col0\" class=\"data row1 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_b622e_row1_col1\" class=\"data row1 col1\" >0.2936</td>\n",
       "      <td id=\"T_b622e_row1_col2\" class=\"data row1 col2\" >0.7076</td>\n",
       "      <td id=\"T_b622e_row1_col3\" class=\"data row1 col3\" >0.2936</td>\n",
       "      <td id=\"T_b622e_row1_col4\" class=\"data row1 col4\" >0.2722</td>\n",
       "      <td id=\"T_b622e_row1_col5\" class=\"data row1 col5\" >0.2697</td>\n",
       "      <td id=\"T_b622e_row1_col6\" class=\"data row1 col6\" >0.2215</td>\n",
       "      <td id=\"T_b622e_row1_col7\" class=\"data row1 col7\" >0.2241</td>\n",
       "      <td id=\"T_b622e_row1_col8\" class=\"data row1 col8\" >0.4045</td>\n",
       "      <td id=\"T_b622e_row1_col9\" class=\"data row1 col9\" >0.1310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b622e_level0_row2\" class=\"row_heading level0 row2\" >rf</th>\n",
       "      <td id=\"T_b622e_row2_col0\" class=\"data row2 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_b622e_row2_col1\" class=\"data row2 col1\" >0.2915</td>\n",
       "      <td id=\"T_b622e_row2_col2\" class=\"data row2 col2\" >0.7493</td>\n",
       "      <td id=\"T_b622e_row2_col3\" class=\"data row2 col3\" >0.2915</td>\n",
       "      <td id=\"T_b622e_row2_col4\" class=\"data row2 col4\" >0.2787</td>\n",
       "      <td id=\"T_b622e_row2_col5\" class=\"data row2 col5\" >0.2708</td>\n",
       "      <td id=\"T_b622e_row2_col6\" class=\"data row2 col6\" >0.2180</td>\n",
       "      <td id=\"T_b622e_row2_col7\" class=\"data row2 col7\" >0.2205</td>\n",
       "      <td id=\"T_b622e_row2_col8\" class=\"data row2 col8\" >0.3984</td>\n",
       "      <td id=\"T_b622e_row2_col9\" class=\"data row2 col9\" >0.1960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b622e_level0_row3\" class=\"row_heading level0 row3\" >xgboost</th>\n",
       "      <td id=\"T_b622e_row3_col0\" class=\"data row3 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_b622e_row3_col1\" class=\"data row3 col1\" >0.2898</td>\n",
       "      <td id=\"T_b622e_row3_col2\" class=\"data row3 col2\" >0.7266</td>\n",
       "      <td id=\"T_b622e_row3_col3\" class=\"data row3 col3\" >0.2898</td>\n",
       "      <td id=\"T_b622e_row3_col4\" class=\"data row3 col4\" >0.2935</td>\n",
       "      <td id=\"T_b622e_row3_col5\" class=\"data row3 col5\" >0.2739</td>\n",
       "      <td id=\"T_b622e_row3_col6\" class=\"data row3 col6\" >0.2174</td>\n",
       "      <td id=\"T_b622e_row3_col7\" class=\"data row3 col7\" >0.2200</td>\n",
       "      <td id=\"T_b622e_row3_col8\" class=\"data row3 col8\" >0.3943</td>\n",
       "      <td id=\"T_b622e_row3_col9\" class=\"data row3 col9\" >0.4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b622e_level0_row4\" class=\"row_heading level0 row4\" >ridge</th>\n",
       "      <td id=\"T_b622e_row4_col0\" class=\"data row4 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_b622e_row4_col1\" class=\"data row4 col1\" >0.2813</td>\n",
       "      <td id=\"T_b622e_row4_col2\" class=\"data row4 col2\" >0.0000</td>\n",
       "      <td id=\"T_b622e_row4_col3\" class=\"data row4 col3\" >0.2813</td>\n",
       "      <td id=\"T_b622e_row4_col4\" class=\"data row4 col4\" >0.2516</td>\n",
       "      <td id=\"T_b622e_row4_col5\" class=\"data row4 col5\" >0.2458</td>\n",
       "      <td id=\"T_b622e_row4_col6\" class=\"data row4 col6\" >0.2068</td>\n",
       "      <td id=\"T_b622e_row4_col7\" class=\"data row4 col7\" >0.2105</td>\n",
       "      <td id=\"T_b622e_row4_col8\" class=\"data row4 col8\" >0.3781</td>\n",
       "      <td id=\"T_b622e_row4_col9\" class=\"data row4 col9\" >0.1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b622e_level0_row5\" class=\"row_heading level0 row5\" >lr</th>\n",
       "      <td id=\"T_b622e_row5_col0\" class=\"data row5 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_b622e_row5_col1\" class=\"data row5 col1\" >0.2792</td>\n",
       "      <td id=\"T_b622e_row5_col2\" class=\"data row5 col2\" >0.7108</td>\n",
       "      <td id=\"T_b622e_row5_col3\" class=\"data row5 col3\" >0.2792</td>\n",
       "      <td id=\"T_b622e_row5_col4\" class=\"data row5 col4\" >0.2632</td>\n",
       "      <td id=\"T_b622e_row5_col5\" class=\"data row5 col5\" >0.2607</td>\n",
       "      <td id=\"T_b622e_row5_col6\" class=\"data row5 col6\" >0.2051</td>\n",
       "      <td id=\"T_b622e_row5_col7\" class=\"data row5 col7\" >0.2073</td>\n",
       "      <td id=\"T_b622e_row5_col8\" class=\"data row5 col8\" >0.3836</td>\n",
       "      <td id=\"T_b622e_row5_col9\" class=\"data row5 col9\" >0.4940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b622e_level0_row6\" class=\"row_heading level0 row6\" >knn</th>\n",
       "      <td id=\"T_b622e_row6_col0\" class=\"data row6 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_b622e_row6_col1\" class=\"data row6 col1\" >0.2733</td>\n",
       "      <td id=\"T_b622e_row6_col2\" class=\"data row6 col2\" >0.6662</td>\n",
       "      <td id=\"T_b622e_row6_col3\" class=\"data row6 col3\" >0.2733</td>\n",
       "      <td id=\"T_b622e_row6_col4\" class=\"data row6 col4\" >0.2222</td>\n",
       "      <td id=\"T_b622e_row6_col5\" class=\"data row6 col5\" >0.2196</td>\n",
       "      <td id=\"T_b622e_row6_col6\" class=\"data row6 col6\" >0.2003</td>\n",
       "      <td id=\"T_b622e_row6_col7\" class=\"data row6 col7\" >0.2086</td>\n",
       "      <td id=\"T_b622e_row6_col8\" class=\"data row6 col8\" >0.3713</td>\n",
       "      <td id=\"T_b622e_row6_col9\" class=\"data row6 col9\" >0.1520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b622e_level0_row7\" class=\"row_heading level0 row7\" >lightgbm</th>\n",
       "      <td id=\"T_b622e_row7_col0\" class=\"data row7 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_b622e_row7_col1\" class=\"data row7 col1\" >0.2695</td>\n",
       "      <td id=\"T_b622e_row7_col2\" class=\"data row7 col2\" >0.7170</td>\n",
       "      <td id=\"T_b622e_row7_col3\" class=\"data row7 col3\" >0.2695</td>\n",
       "      <td id=\"T_b622e_row7_col4\" class=\"data row7 col4\" >0.2573</td>\n",
       "      <td id=\"T_b622e_row7_col5\" class=\"data row7 col5\" >0.2505</td>\n",
       "      <td id=\"T_b622e_row7_col6\" class=\"data row7 col6\" >0.1947</td>\n",
       "      <td id=\"T_b622e_row7_col7\" class=\"data row7 col7\" >0.1971</td>\n",
       "      <td id=\"T_b622e_row7_col8\" class=\"data row7 col8\" >0.3799</td>\n",
       "      <td id=\"T_b622e_row7_col9\" class=\"data row7 col9\" >0.4710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b622e_level0_row8\" class=\"row_heading level0 row8\" >gbc</th>\n",
       "      <td id=\"T_b622e_row8_col0\" class=\"data row8 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_b622e_row8_col1\" class=\"data row8 col1\" >0.2654</td>\n",
       "      <td id=\"T_b622e_row8_col2\" class=\"data row8 col2\" >0.7247</td>\n",
       "      <td id=\"T_b622e_row8_col3\" class=\"data row8 col3\" >0.2654</td>\n",
       "      <td id=\"T_b622e_row8_col4\" class=\"data row8 col4\" >0.2678</td>\n",
       "      <td id=\"T_b622e_row8_col5\" class=\"data row8 col5\" >0.2547</td>\n",
       "      <td id=\"T_b622e_row8_col6\" class=\"data row8 col6\" >0.1886</td>\n",
       "      <td id=\"T_b622e_row8_col7\" class=\"data row8 col7\" >0.1907</td>\n",
       "      <td id=\"T_b622e_row8_col8\" class=\"data row8 col8\" >0.3773</td>\n",
       "      <td id=\"T_b622e_row8_col9\" class=\"data row8 col9\" >0.5100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b622e_level0_row9\" class=\"row_heading level0 row9\" >svm</th>\n",
       "      <td id=\"T_b622e_row9_col0\" class=\"data row9 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_b622e_row9_col1\" class=\"data row9 col1\" >0.2350</td>\n",
       "      <td id=\"T_b622e_row9_col2\" class=\"data row9 col2\" >0.0000</td>\n",
       "      <td id=\"T_b622e_row9_col3\" class=\"data row9 col3\" >0.2350</td>\n",
       "      <td id=\"T_b622e_row9_col4\" class=\"data row9 col4\" >0.2298</td>\n",
       "      <td id=\"T_b622e_row9_col5\" class=\"data row9 col5\" >0.2146</td>\n",
       "      <td id=\"T_b622e_row9_col6\" class=\"data row9 col6\" >0.1565</td>\n",
       "      <td id=\"T_b622e_row9_col7\" class=\"data row9 col7\" >0.1611</td>\n",
       "      <td id=\"T_b622e_row9_col8\" class=\"data row9 col8\" >0.3467</td>\n",
       "      <td id=\"T_b622e_row9_col9\" class=\"data row9 col9\" >0.1430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b622e_level0_row10\" class=\"row_heading level0 row10\" >nb</th>\n",
       "      <td id=\"T_b622e_row10_col0\" class=\"data row10 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_b622e_row10_col1\" class=\"data row10 col1\" >0.2226</td>\n",
       "      <td id=\"T_b622e_row10_col2\" class=\"data row10 col2\" >0.6955</td>\n",
       "      <td id=\"T_b622e_row10_col3\" class=\"data row10 col3\" >0.2226</td>\n",
       "      <td id=\"T_b622e_row10_col4\" class=\"data row10 col4\" >0.1846</td>\n",
       "      <td id=\"T_b622e_row10_col5\" class=\"data row10 col5\" >0.1575</td>\n",
       "      <td id=\"T_b622e_row10_col6\" class=\"data row10 col6\" >0.1490</td>\n",
       "      <td id=\"T_b622e_row10_col7\" class=\"data row10 col7\" >0.1719</td>\n",
       "      <td id=\"T_b622e_row10_col8\" class=\"data row10 col8\" >0.3872</td>\n",
       "      <td id=\"T_b622e_row10_col9\" class=\"data row10 col9\" >0.1240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b622e_level0_row11\" class=\"row_heading level0 row11\" >dt</th>\n",
       "      <td id=\"T_b622e_row11_col0\" class=\"data row11 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_b622e_row11_col1\" class=\"data row11 col1\" >0.2167</td>\n",
       "      <td id=\"T_b622e_row11_col2\" class=\"data row11 col2\" >0.5685</td>\n",
       "      <td id=\"T_b622e_row11_col3\" class=\"data row11 col3\" >0.2167</td>\n",
       "      <td id=\"T_b622e_row11_col4\" class=\"data row11 col4\" >0.2121</td>\n",
       "      <td id=\"T_b622e_row11_col5\" class=\"data row11 col5\" >0.2043</td>\n",
       "      <td id=\"T_b622e_row11_col6\" class=\"data row11 col6\" >0.1369</td>\n",
       "      <td id=\"T_b622e_row11_col7\" class=\"data row11 col7\" >0.1384</td>\n",
       "      <td id=\"T_b622e_row11_col8\" class=\"data row11 col8\" >0.3235</td>\n",
       "      <td id=\"T_b622e_row11_col9\" class=\"data row11 col9\" >0.1260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b622e_level0_row12\" class=\"row_heading level0 row12\" >ada</th>\n",
       "      <td id=\"T_b622e_row12_col0\" class=\"data row12 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_b622e_row12_col1\" class=\"data row12 col1\" >0.1983</td>\n",
       "      <td id=\"T_b622e_row12_col2\" class=\"data row12 col2\" >0.6516</td>\n",
       "      <td id=\"T_b622e_row12_col3\" class=\"data row12 col3\" >0.1983</td>\n",
       "      <td id=\"T_b622e_row12_col4\" class=\"data row12 col4\" >0.1930</td>\n",
       "      <td id=\"T_b622e_row12_col5\" class=\"data row12 col5\" >0.1733</td>\n",
       "      <td id=\"T_b622e_row12_col6\" class=\"data row12 col6\" >0.1194</td>\n",
       "      <td id=\"T_b622e_row12_col7\" class=\"data row12 col7\" >0.1230</td>\n",
       "      <td id=\"T_b622e_row12_col8\" class=\"data row12 col8\" >0.3027</td>\n",
       "      <td id=\"T_b622e_row12_col9\" class=\"data row12 col9\" >0.1440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b622e_level0_row13\" class=\"row_heading level0 row13\" >dummy</th>\n",
       "      <td id=\"T_b622e_row13_col0\" class=\"data row13 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_b622e_row13_col1\" class=\"data row13 col1\" >0.1194</td>\n",
       "      <td id=\"T_b622e_row13_col2\" class=\"data row13 col2\" >0.5000</td>\n",
       "      <td id=\"T_b622e_row13_col3\" class=\"data row13 col3\" >0.1194</td>\n",
       "      <td id=\"T_b622e_row13_col4\" class=\"data row13 col4\" >0.0143</td>\n",
       "      <td id=\"T_b622e_row13_col5\" class=\"data row13 col5\" >0.0255</td>\n",
       "      <td id=\"T_b622e_row13_col6\" class=\"data row13 col6\" >0.0000</td>\n",
       "      <td id=\"T_b622e_row13_col7\" class=\"data row13 col7\" >0.0000</td>\n",
       "      <td id=\"T_b622e_row13_col8\" class=\"data row13 col8\" >0.2620</td>\n",
       "      <td id=\"T_b622e_row13_col9\" class=\"data row13 col9\" >0.1420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b622e_level0_row14\" class=\"row_heading level0 row14\" >qda</th>\n",
       "      <td id=\"T_b622e_row14_col0\" class=\"data row14 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_b622e_row14_col1\" class=\"data row14 col1\" >0.0970</td>\n",
       "      <td id=\"T_b622e_row14_col2\" class=\"data row14 col2\" >0.5043</td>\n",
       "      <td id=\"T_b622e_row14_col3\" class=\"data row14 col3\" >0.0970</td>\n",
       "      <td id=\"T_b622e_row14_col4\" class=\"data row14 col4\" >0.0851</td>\n",
       "      <td id=\"T_b622e_row14_col5\" class=\"data row14 col5\" >0.0816</td>\n",
       "      <td id=\"T_b622e_row14_col6\" class=\"data row14 col6\" >0.0090</td>\n",
       "      <td id=\"T_b622e_row14_col7\" class=\"data row14 col7\" >0.0091</td>\n",
       "      <td id=\"T_b622e_row14_col8\" class=\"data row14 col8\" >0.2501</td>\n",
       "      <td id=\"T_b622e_row14_col9\" class=\"data row14 col9\" >0.1300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x20ba0e8b908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best = compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fa5d04-7f8f-434d-ac54-a8e4dc6186bb",
   "metadata": {},
   "source": [
    "# Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dda847f7-28cc-410b-93fc-38faf8149d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6fc3454-02ab-47a2-bf86-e1ece53e2411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda(trial):\n",
    "    solver = trial.suggest_categorical('solver', ['svd', 'lsqr', 'eigen'])\n",
    "    tol = trial.suggest_loguniform('tol', 1e-8, 10.0)\n",
    "          \n",
    "    model = LinearDiscriminantAnalysis(\n",
    "        solver=solver,\n",
    "        tol=tol\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(rskf.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict_proba(X_test)\n",
    "\n",
    "        sorted_pred_idx = np.argsort(-y_pred, axis=1)[:,:3]\n",
    "        original_shape = sorted_pred_idx.shape\n",
    "        top3_pred = encoder.inverse_transform(sorted_pred_idx.reshape(-1,1))\n",
    "        top3_pred = top3_pred.reshape(original_shape)\n",
    "        results.append(mapk(y_test.reshape(-1, 1), sorted_pred_idx, k=3))\n",
    "    \n",
    "    return np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3542fc0-b5bb-4db7-bb0f-3e64ec6751ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge(trial):\n",
    "    alpha = trial.suggest_int('alpha', 0, 1000)\n",
    "    tol = trial.suggest_loguniform('tol', 1e-8, 10.0)\n",
    "        \n",
    "    model = RidgeClassifier(\n",
    "        alpha=alpha,\n",
    "        tol=tol\n",
    "    )\n",
    "    calibrated_model = CalibratedClassifierCV(model, method='sigmoid')\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(rskf.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        calibrated_model.fit(X_train, y_train)\n",
    "        y_pred = calibrated_model.predict_proba(X_test)\n",
    "\n",
    "        sorted_pred_idx = np.argsort(-y_pred, axis=1)[:,:3]\n",
    "        original_shape = sorted_pred_idx.shape\n",
    "        top3_pred = encoder.inverse_transform(sorted_pred_idx.reshape(-1,1))\n",
    "        top3_pred = top3_pred.reshape(original_shape)\n",
    "        results.append(mapk(y_test.reshape(-1, 1), sorted_pred_idx, k=3))\n",
    "    \n",
    "    return np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e04075c3-c502-466c-b1b0-5fee4959f915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf(trial):\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 100)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 500)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 100)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 100)\n",
    "    random_state = 0\n",
    "          \n",
    "    model = RandomForestClassifier(\n",
    "        max_depth=max_depth,\n",
    "        n_estimators=n_estimators,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        min_samples_split=min_samples_split,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(rskf.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict_proba(X_test)\n",
    "\n",
    "        sorted_pred_idx = np.argsort(-y_pred, axis=1)[:,:3]\n",
    "        original_shape = sorted_pred_idx.shape\n",
    "        top3_pred = encoder.inverse_transform(sorted_pred_idx.reshape(-1,1))\n",
    "        top3_pred = top3_pred.reshape(original_shape)\n",
    "        results.append(mapk(y_test.reshape(-1, 1), sorted_pred_idx, k=3))\n",
    "    \n",
    "    return np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8aec7962-4362-4285-afaa-5dd7e17bc0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.1, 1),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.1, 1),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-10, 1),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-10, 1),\n",
    "        'gamma': trial.suggest_loguniform('gamma', 1e-10, 1),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'random_state': 0,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    \n",
    "    model = XGBClassifier(**params)\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(rskf.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict_proba(X_test)\n",
    "\n",
    "        sorted_pred_idx = np.argsort(-y_pred, axis=1)[:,:3]\n",
    "        original_shape = sorted_pred_idx.shape\n",
    "        top3_pred = encoder.inverse_transform(sorted_pred_idx.reshape(-1,1))\n",
    "        top3_pred = top3_pred.reshape(original_shape)\n",
    "        results.append(mapk(y_test.reshape(-1, 1), sorted_pred_idx, k=3))\n",
    "    \n",
    "    return np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f55fee8-d35e-4007-a2c3-e891ffaea5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def et(trial):\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 100)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 500)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 100)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 100)\n",
    "    max_features = trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2', None])\n",
    "    random_state = 0\n",
    "\n",
    "          \n",
    "    model = ExtraTreesClassifier(\n",
    "        max_depth=max_depth,\n",
    "        n_estimators=n_estimators,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        min_samples_split=min_samples_split,\n",
    "        max_features=max_features,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(rskf.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict_proba(X_test)\n",
    "\n",
    "        sorted_pred_idx = np.argsort(-y_pred, axis=1)[:,:3]\n",
    "        original_shape = sorted_pred_idx.shape\n",
    "        top3_pred = encoder.inverse_transform(sorted_pred_idx.reshape(-1,1))\n",
    "        top3_pred = top3_pred.reshape(original_shape)\n",
    "        results.append(mapk(y_test.reshape(-1, 1), sorted_pred_idx, k=3))\n",
    "    \n",
    "    return np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a56a5c4c-c4f9-47c7-accc-665868f34702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbc(trial):\n",
    "    #tol = trial.suggest_loguniform('tol', 1e-8, 10.0)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 50)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', .001, 1)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 500)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 100)\n",
    "    max_leaf_nodes = trial.suggest_int('max_leaf_nodes', 2, 100)\n",
    "    random_state = 0\n",
    "          \n",
    "    model = GradientBoostingClassifier(\n",
    "        #tol=tol,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_leaf_nodes=max_leaf_nodes,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(rskf.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict_proba(X_test)\n",
    "\n",
    "        sorted_pred_idx = np.argsort(-y_pred, axis=1)[:,:3]\n",
    "        original_shape = sorted_pred_idx.shape\n",
    "        top3_pred = encoder.inverse_transform(sorted_pred_idx.reshape(-1,1))\n",
    "        top3_pred = top3_pred.reshape(original_shape)\n",
    "        results.append(mapk(y_test.reshape(-1, 1), sorted_pred_idx, k=3))\n",
    "    \n",
    "    return np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7915b3fe-4fb0-4d7e-8951-6589dce52594",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# study = optuna.create_study(direction='maximize')\n",
    "# optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "# study.optimize(lda, n_trials=100)\n",
    "# study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f04f80e-53a4-4ad8-8fdc-b3626c25643f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# study = optuna.create_study(direction='maximize')\n",
    "# optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "# study.optimize(ridge, n_trials=100)\n",
    "# study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d402fbc-7607-4a37-acdb-14fd5e571d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study = optuna.create_study(direction='maximize')\n",
    "# optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "# study.optimize(rf, n_trials=100)\n",
    "# study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1702308-cbb3-4cf3-9b15-71474e8b3f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study = optuna.create_study(direction='maximize')\n",
    "# optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "# study.optimize(xgb, n_trials=100)\n",
    "# study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b398c88c-bcce-49bc-96de-f7f4e45dba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study = optuna.create_study(direction='maximize')\n",
    "# optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "# study.optimize(et, n_trials=100)\n",
    "# study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0be86627-57b2-4783-b40e-af9a41d00220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study = optuna.create_study(direction='maximize')\n",
    "# optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "# study.optimize(gbc, n_trials=100)\n",
    "# study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a334275d-47c9-491b-bad7-823c8e7a763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_params = {\n",
    "    'solver': 'eigen', \n",
    "    'tol': 2.7614720614865225e-06\n",
    "}\n",
    "\n",
    "ridge_params = {\n",
    "    'alpha': 365, \n",
    "    'tol': 0.42705446738501834\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'max_depth': 27,\n",
    "    'n_estimators': 430,\n",
    "    'min_samples_leaf': 1,\n",
    "    'min_samples_split': 28\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': 993,\n",
    "    'max_depth': 5,\n",
    "    'learning_rate': 0.005433316626408222,\n",
    "    'subsample': 0.7946220685545012,\n",
    "    'colsample_bytree': 0.23406190765836787,\n",
    "    'reg_alpha': 5.571859953931e-07,\n",
    "    'reg_lambda': 4.8441369828589075e-08,\n",
    "    'gamma': 1.0396193273787708e-08,\n",
    "    'min_child_weight': 1\n",
    "}\n",
    "\n",
    "et_params = {\n",
    "    'max_depth': 100,\n",
    "    'n_estimators': 376,\n",
    "    'min_samples_leaf': 1,\n",
    "    'min_samples_split': 29,\n",
    "    'max_features': 'log2'\n",
    "}\n",
    "\n",
    "gbc_params = {\n",
    "    'max_depth': 24,\n",
    "    'learning_rate': 0.007593638696418762,\n",
    "    'n_estimators': 335,\n",
    "    'min_samples_leaf': 74,\n",
    "    'max_leaf_nodes': 71\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa65aea4-7706-498b-a7b6-1d5909261674",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LinearDiscriminantAnalysis(**lda_params)\n",
    "ridge_model = CalibratedClassifierCV(RidgeClassifier(**ridge_params), method='sigmoid')\n",
    "rf_model = RandomForestClassifier(**rf_params)\n",
    "xgb_model = XGBClassifier(**xgb_params)\n",
    "et_model = ExtraTreesClassifier(**et_params)\n",
    "gbc_model = GradientBoostingClassifier(**gbc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f936e36-655e-4dba-8148-9c16c31194f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'lda': lda_model, \n",
    "    'ridge': ridge_model, \n",
    "    'rf': rf_model,\n",
    "    'xgb': xgb_model,\n",
    "    'et': et_model,\n",
    "    'gbc': gbc_model\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc35577d-f52c-48de-9a5d-9280d185e453",
   "metadata": {},
   "source": [
    "# Models Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "755cf9a2-7e1b-4f74-8c13-5ffa086a7b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:15:31] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:15:35] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:15:39] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:15:44] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:15:48] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:15:53] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:15:57] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:02] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:07] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:11] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:16] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:20] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:25] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:29] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:34] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:38] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:43] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:47] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:52] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:16:56] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:01] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:05] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:10] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:14] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:19] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:24] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:28] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:33] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:37] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:42] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "results_ensemble_models = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    res=[]\n",
    "    for i, (train_index, test_index) in enumerate(rskf.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict_proba(X_test)\n",
    "\n",
    "        sorted_pred_idx = np.argsort(-y_pred, axis=1)[:,:3]\n",
    "        original_shape = sorted_pred_idx.shape\n",
    "        top3_pred = encoder.inverse_transform(sorted_pred_idx.reshape(-1,1))\n",
    "        top3_pred = top3_pred.reshape(original_shape)\n",
    "        res.append(mapk(y_test.reshape(-1, 1), sorted_pred_idx, k=3))\n",
    "    results_ensemble_models[name] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7505e452-f7ba-44b5-b82f-34b19f7169d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "lda\n",
      "0.3360060362173038\n",
      "0.03863673924660182\n",
      "----------\n",
      "ridge\n",
      "0.3521607422311648\n",
      "0.04248849201729114\n",
      "----------\n",
      "rf\n",
      "0.3636966241895819\n",
      "0.03254981391944133\n",
      "----------\n",
      "xgb\n",
      "0.36821596244131444\n",
      "0.03806163894767955\n",
      "----------\n",
      "et\n",
      "0.36490274983232734\n",
      "0.03921634245095327\n",
      "----------\n",
      "gbc\n",
      "0.3553018108651911\n",
      "0.04075270870208064\n"
     ]
    }
   ],
   "source": [
    "for name, result in results_ensemble_models.items():\n",
    "    print(\"----------\\n\" + name)\n",
    "    print(np.mean(result))\n",
    "    print(np.std(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1bd835-0454-44d2-9a54-54fb94f2c884",
   "metadata": {},
   "source": [
    "# Bagging Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c36de4ed-13d7-4ba8-90ca-d5dbf9d01d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = VotingClassifier(estimators=[('lda', lda_model), \n",
    "                                           ('ridge', ridge_model), \n",
    "                                           ('rf', rf_model),\n",
    "                                           ('xgb', xgb_model),\n",
    "                                           ('et', et_model),\n",
    "                                           ('gbc', gbc_model)], \n",
    "                               voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b92f60b-7154-41da-b4d2-41cd05b322b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:26:34] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:39] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:45] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:50] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:55] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:00] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:06] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:11] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:16] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:21] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:26] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:31] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:36] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:41] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:46] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:51] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:27:57] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:02] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:07] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:12] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:17] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:22] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:28] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:33] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:38] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:43] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:48] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:53] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:28:58] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:29:03] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.37482003129890457\n"
     ]
    }
   ],
   "source": [
    "final_model = VotingClassifier(estimators=[('rf', rf_model),\n",
    "                                           ('xgb', xgb_model),\n",
    "                                           ('et', et_model)], \n",
    "                               voting='soft')\n",
    "\n",
    "results_ensemble = []\n",
    "    \n",
    "for i, (train_index, test_index) in enumerate(rskf.split(X, y)):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    final_model.fit(X_train, y_train)\n",
    "    y_pred = final_model.predict_proba(X_test)\n",
    "\n",
    "    sorted_pred_idx = np.argsort(-y_pred, axis=1)[:,:3]\n",
    "    original_shape = sorted_pred_idx.shape\n",
    "    top3_pred = encoder.inverse_transform(sorted_pred_idx.reshape(-1,1))\n",
    "    top3_pred = top3_pred.reshape(original_shape)\n",
    "    results_ensemble.append(mapk(y_test.reshape(-1, 1), sorted_pred_idx, k=3))\n",
    "\n",
    "print(np.mean(results_ensemble))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9adff72-8331-4647-80cf-04ed1bc1c454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:21:20] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:21:30] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:21:40] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:21:49] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:21:59] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:09] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:19] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:29] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:38] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:48] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:22:58] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:08] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:18] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:28] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:38] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:49] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:23:58] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:08] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:17] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:28] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:38] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:48] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:24:58] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:08] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:18] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:28] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:37] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:47] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:25:57] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:26:07] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.3654035323049408\n"
     ]
    }
   ],
   "source": [
    "results_ensemble = []\n",
    "    \n",
    "for i, (train_index, test_index) in enumerate(rskf.split(X, y)):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    final_model.fit(X_train, y_train)\n",
    "    y_pred = final_model.predict_proba(X_test)\n",
    "\n",
    "    sorted_pred_idx = np.argsort(-y_pred, axis=1)[:,:3]\n",
    "    original_shape = sorted_pred_idx.shape\n",
    "    top3_pred = encoder.inverse_transform(sorted_pred_idx.reshape(-1,1))\n",
    "    top3_pred = top3_pred.reshape(original_shape)\n",
    "    results_ensemble.append(mapk(y_test.reshape(-1, 1), sorted_pred_idx, k=3))\n",
    "\n",
    "print(np.mean(results_ensemble))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6481d224-b295-4200-be10-ee2635a49411",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78f848ef-5607-4dbe-b70d-23b0ed872284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:29:23] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf',\n",
       "                              RandomForestClassifier(bootstrap=True,\n",
       "                                                     ccp_alpha=0.0,\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth=27,\n",
       "                                                     max_features='auto',\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     max_samples=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=28,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     n_estimators=430,\n",
       "                                                     n_jobs=None,\n",
       "                                                     oob_score=False,\n",
       "                                                     random_state=None,...\n",
       "                                                   criterion='gini',\n",
       "                                                   max_depth=100,\n",
       "                                                   max_features='log2',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   max_samples=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=29,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators=376,\n",
       "                                                   n_jobs=None, oob_score=False,\n",
       "                                                   random_state=None, verbose=0,\n",
       "                                                   warm_start=False))],\n",
       "                 flatten_transform=True, n_jobs=None, verbose=False,\n",
       "                 voting='soft', weights=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5234ee7-ae92-4754-8f98-19cc3eb79643",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4b4f767e-e67b-4033-a6bc-6cd6e381e67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = final_model.predict_proba(test)\n",
    "\n",
    "sorted_pred_idx = np.argsort(-final_predictions, axis=1)[:,:3]\n",
    "original_shape = sorted_pred_idx.shape\n",
    "top3_pred = encoder.inverse_transform(sorted_pred_idx.reshape(-1,1))\n",
    "top3_pred = top3_pred.reshape(original_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54c1dee-2041-4fb3-9aa9-6204428ccdcd",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "01744e02-5e7a-4f3a-8780-35c9a97b88f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission['prognosis'] = np.apply_along_axis(lambda x: np.array(' '.join(x), dtype=\"object\"), 1, top3_pred)\n",
    "submission.to_csv('submission_bagging_model.csv', columns=['id', 'prognosis'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b387206e-c929-450c-a8b7-c008b0691bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
